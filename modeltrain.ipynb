{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "modeltrain.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smuje6cN5BGA",
        "colab_type": "code",
        "outputId": "20776086-310b-4cfc-c450-6ba94a5216bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "!pip install mnist\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert data to numpy arrays and normalize images to the interval [0, 1]\n",
        "X_train = np.array(X_train) / 255.0\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test) / 255.0\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8FNLrr85BGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping all images into 28*28 for pre-processing\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scFzZ38Q5BGI",
        "colab_type": "code",
        "outputId": "64f33cef-cc46-43a3-80ae-3fb84d5912a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#Display a random image\n",
        "plt.imshow(y_train[1])\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0cb921a1c2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Display a random image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5613\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5615\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5616\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape () for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDhvKOJK5BGM",
        "colab_type": "code",
        "outputId": "fe44d866-2c7e-43d1-b3ca-7368ca97d662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Y'all can see how an image array looks like. all float values b/w 0 and 1\n",
        "m = X_train[2]\n",
        "print(m)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.2627451  0.90980392 0.15294118 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.24313725 0.31764706\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.47058824 0.70588235 0.15294118 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.49411765 0.63921569\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00784314 0.6        0.82352941 0.15686275 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.8627451  0.63921569\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.10588235 0.99607843 0.63529412 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.87058824 0.63921569\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.71764706 0.99607843 0.49019608 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.18039216 0.96078431 0.63921569\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.77647059 0.99607843 0.21960784 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.47058824 0.99607843 0.63921569\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.09019608 0.90588235 0.99607843 0.11372549 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.62352941 0.99607843 0.47058824\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.63921569 0.99607843 0.84705882 0.0627451  0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.62352941 0.99607843 0.2627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.05490196 0.3372549  0.69803922\n",
            "  0.97254902 0.99607843 0.35686275 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.62352941 0.99607843 0.33333333\n",
            "  0.         0.         0.         0.18431373 0.19215686 0.45490196\n",
            "  0.56470588 0.58823529 0.94509804 0.95294118 0.91764706 0.70196078\n",
            "  0.94509804 0.98823529 0.15686275 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.58823529 0.99215686 0.92941176\n",
            "  0.81176471 0.81176471 0.81176471 0.99215686 0.99607843 0.98039216\n",
            "  0.94117647 0.77647059 0.56078431 0.35686275 0.10980392 0.01960784\n",
            "  0.91372549 0.98039216 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.46666667 0.69411765\n",
            "  0.69411765 0.69411765 0.69411765 0.69411765 0.38431373 0.21960784\n",
            "  0.         0.         0.         0.         0.         0.4\n",
            "  0.99607843 0.8627451  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6627451\n",
            "  0.99607843 0.5372549  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6627451\n",
            "  0.99607843 0.22352941 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6627451\n",
            "  0.99607843 0.22352941 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6627451\n",
            "  1.         0.36862745 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6627451\n",
            "  0.99607843 0.37647059 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6627451\n",
            "  0.99607843 0.6        0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6627451\n",
            "  1.         0.6        0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.37647059\n",
            "  0.99607843 0.6        0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJMy71Lp5BGP",
        "colab_type": "code",
        "outputId": "4b2708cd-4466-49d2-bc5e-1f6d177f2523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "#for train data\n",
        "print(len(X_train)+10)\n",
        "for t in range(len(X_train)):\n",
        "    X_train[t]=np.transpose(X_train[t])\n",
        "    \n",
        "#checking\n",
        "plt.imshow(X_train[0])\n",
        "plt.show\n",
        "\n",
        "#for test data  \n",
        "for t in range(len(X_test)):\n",
        "    X_test[t]=np.transpose(X_test[t])\n",
        "\n",
        "#checking\n",
        "plt.imshow(X_test[1])\n",
        "plt.show\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjBZT4cY5BGT",
        "colab_type": "code",
        "outputId": "3518a099-b66f-41cb-9880-a778023396b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "\n",
        "m = X_train[len(X_train)-1]\n",
        "print(y_train[len(X_train)-1])\n",
        "plt.imshow(m)\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2IEgCDsQxP8DNv5KY80mvKgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6mEWCLB5BGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 784,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 784,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoZOsKsD5BGb",
        "colab_type": "code",
        "outputId": "4ec47431-f5a1-4fe4-c82f-fa4a04080767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM\n",
        "from keras import backend as K\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.constraints import maxnorm\n",
        "def resh(ipar):\n",
        "    opar = []\n",
        "    for image in ipar:\n",
        "        opar.append(image.reshape(-1))\n",
        "    return np.asarray(opar)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "train_images = X_train.astype('float32')\n",
        "test_images = X_test.astype('float32')\n",
        "\n",
        "train_images = resh(train_images)\n",
        "test_images = resh(test_images)\n",
        "\n",
        "\n",
        "train_labels = np_utils.to_categorical(y_train, 62)\n",
        "test_labels = np_utils.to_categorical(y_test, 62)\n",
        "\n",
        "\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Reshape((28,28,1), input_shape=(784,)))\n",
        "\n",
        "model.add(Conv2D(20, (3, 3), padding=\"same\", input_shape=(30, 30, 1), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(48, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(62, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 20)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 48)        8688      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 48)        192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 48)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2352)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               301184    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 62)                7998      \n",
            "=================================================================\n",
            "Total params: 318,262\n",
            "Trainable params: 318,166\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma8P-L6Z5BGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSsIXw945BGj",
        "colab_type": "code",
        "outputId": "d3d3fff1-d9cb-447b-d761-6ae29b75a9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.summary())\n",
        "estop = EarlyStopping(patience=10, mode='min', min_delta=0.001, monitor='val_loss')\n",
        "history = model.fit(train_images,train_labels,validation_data=(test_images, test_labels), batch_size=128, epochs=100,callbacks=[estop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 20)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 48)        8688      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 48)        192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 48)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2352)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               301184    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 62)                7998      \n",
            "=================================================================\n",
            "Total params: 318,262\n",
            "Trainable params: 318,166\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0963 - acc: 0.9708 - val_loss: 0.0651 - val_acc: 0.9807\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 60s 1ms/step - loss: 0.0587 - acc: 0.9828 - val_loss: 0.0516 - val_acc: 0.9849\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 59s 988us/step - loss: 0.0434 - acc: 0.9859 - val_loss: 0.0445 - val_acc: 0.9864\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 56s 940us/step - loss: 0.0349 - acc: 0.9889 - val_loss: 0.0453 - val_acc: 0.9857\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 56s 928us/step - loss: 0.0286 - acc: 0.9909 - val_loss: 0.0425 - val_acc: 0.9861\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 55s 921us/step - loss: 0.0261 - acc: 0.9914 - val_loss: 0.0480 - val_acc: 0.9861\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 55s 911us/step - loss: 0.0240 - acc: 0.9923 - val_loss: 0.0440 - val_acc: 0.9878\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 54s 902us/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0385 - val_acc: 0.9890\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 54s 904us/step - loss: 0.0186 - acc: 0.9939 - val_loss: 0.0368 - val_acc: 0.9877\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0481 - val_acc: 0.9871\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0440 - val_acc: 0.9891\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 54s 898us/step - loss: 0.0151 - acc: 0.9951 - val_loss: 0.0522 - val_acc: 0.9868\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 53s 885us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0536 - val_acc: 0.9879\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 53s 882us/step - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0457 - val_acc: 0.9892\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 53s 879us/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0444 - val_acc: 0.9895\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 53s 876us/step - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0445 - val_acc: 0.9896\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 53s 877us/step - loss: 0.0128 - acc: 0.9957 - val_loss: 0.0568 - val_acc: 0.9890\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 53s 882us/step - loss: 0.0130 - acc: 0.9956 - val_loss: 0.0470 - val_acc: 0.9886\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 52s 875us/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0471 - val_acc: 0.9897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn2CrYQo5BGm",
        "colab_type": "code",
        "outputId": "0e580f2e-d024-42f8-eec8-ae8ea3ecd835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.save(\"mymodel.h5\")\n",
        "from google.colab import files\n",
        "files.download(\"/content/mymodel.h5\")\n",
        "scores = model.evaluate(test_images,test_labels, verbose = 0)\n",
        "print(\"Accuracy: %.2f%%\"%(scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ2V0bhW5BGq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGL4k7Ho5BGq",
        "colab_type": "code",
        "outputId": "45af9fde-f962-4a0c-c28b-b7dd011b8515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "m = X_test[258].reshape(28,28)\n",
        "print(y_test[258])\n",
        "plt.imshow(m)\n",
        "plt.show\n",
        "print('prediction: '+str(model.predict_classes(X_test[258].reshape(1,784))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "prediction: [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHUiCsANJEHYgCcIOJPH/rAcwj4lFG1sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA3xTGQ65BGt",
        "colab_type": "text"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ_HBebp5BGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "    \n",
        "model.save_weights(\"model.h5\")\n",
        "files.download(\"/content/model.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8VWRjvxCD8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}